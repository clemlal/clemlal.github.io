<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Mathematics of Machine Learning M2 MAPI3 (Paul Sabatier, 2024-2025)</title>
    <link rel="stylesheet" href="../../css/styles.css">
</head>
<body>
    <div class="container">
        <main class="main">
            <div id="toptitle">
                <h1>Mathematics of Machine Learning M2 MAPI3 (Paul Sabatier, 2024-2025)</h1>

                <strong>Lecturers : </strong> <a href="../../index.html" target="_blank" rel="noopener noreferrer">Clément Lalanne</a>
            </div>
            <div id="content">
                <!-- Content specific to this lecture -->
                <h2>Overview</h2>
                <p>This class aims at introducing the main theoretical groundings of modern machine learning, with an emphasis on supervised learning. It requires basic notions of linear algebra and of probability theory (with the formalism of measure theory). For the last lectures, having some basic notions of functionnal analysis is recommended.</p>
            </div>

            <h2>References and external resources</h2>

            <h3>Machine Learning and Learning Theory</h3>

            <ul>
                <li><a href="https://www.di.ens.fr/~fbach/ltfp_book.pdf" target="_blank" rel="noopener noreferrer">Learning Theory from First Principles</a>, <a href="https://www.di.ens.fr/~fbach/" target="_blank" rel="noopener noreferrer">Francis Bach</a>, 2024 : <strong>Main reference which served as base material for this course</strong>.</li>

                <li><a href="https://cs.nyu.edu/~mohri/mlbook/" target="_blank" rel="noopener noreferrer">Foundations of Machine Learning</a>, Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar, 2018.</li>

                <li><a href="https://perso.ens-lyon.fr/aurelien.garivier/www.math.univ-toulouse.fr/_agarivie/index.html" target="_blank" rel="noopener noreferrer">Aurélien Garivier</a>'s <a href="https://perso.ens-lyon.fr/aurelien.garivier/www.math.univ-toulouse.fr/_agarivie/index2baa.html?q=node/214" target="_blank" rel="noopener noreferrer">ML M2 class</a> at ENS Lyon : Some of the topics are complementary to the ones presented in this class.</li>
           </ul>

            <h3>Optimization for Machine Learning</h3>

            <ul>
                <li><a href="https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf" target="_blank" rel="noopener noreferrer">Convex Optimization</a>, Stephen Boyd, and Lieven Vandenberghe, Cambridge University Press, 2012.</li>

                <li><a href="https://epubs.siam.org/doi/book/10.1137/1.9781611974997" target="_blank" rel="noopener noreferrer">First-Order Optimization Methods</a>, Amir Beck, 2017.</li>
            
            </ul>

            <h3>Measure and Probability Theory</h3>

            <ul>
                <li><a href="https://www.imo.universite-paris-saclay.fr/~jean-francois.le-gall/IPPA2.pdf" target="_blank" rel="noopener noreferrer">Intégration, Probabilités et Processus Aléatoires</a>, Jean-François Le Gall, 2006 : Nice introduction to measure theory which also contains elements of stochastic processes and the construction of the conditional expectation.</li>

                <li>Probabilités 2, Jean-Yves Ouvrard, 2009 : More details on the advanced topics of the previous reference.</li>

                <li>Concentration Inequalities: A Nonasymptotic Theory of Independence,  Stéphane Boucheron, Gábor Lugosi, Pascal Massart, 2013</li>
            </ul>

            <h3>Analysis</h3>

            <ul>
                <li><a href="http://www.cmap.polytechnique.fr/~massot/MAP431_web/MAP431_Histoire_Massot/Livres_Bony_Lutzen/Jean-Michel%20Bony-Cours%20d%27analyse.%20The%CC%81orie%20des%20distributions%20et%20analyse%20de%20Fourier-Ellipses(2001).pdf" target="_blank" rel="noopener noreferrer">Cours d'analyse</a>, Jean-Michel Bony, 2001.</li>
            </ul>

            <h2>Evaluation</h2>
            <p>The evaluation for this class will be split between a mid-term homework (1/3 of the final grade) and a final exam (2/3 of the final grade).</p>

            <p><strong>Important Notes :</strong>
            <ul>
                <li>The homework will appear on this page during October with the due date. Please check this page periodically in order to not miss it.</li>
                <li>The homeworks will be scanned with an AI similarity detection software (works with handwriting). You are warned, do not copy.</li>
            </ul></p>
            

            <h2>Homework</h2>

            <h2>Lectures</h2>
            <ul>
                <li><strong>Lecture 1 </strong> (02/09/2024 - 13:30-15:30) : <a href="MachineLearningMAPI3Lecture1Introduction.pdf" target="_blank" rel="noopener noreferrer">Introduction to Supervised Learning</a>.</li>

                <li><strong>Lecture 2 </strong> (04/09/2024 - 13:30-15:30) : <a href="MachineLearningMAPI3Lecture2RegressionsLinearRidge.pdf" target="_blank" rel="noopener noreferrer">Linear Regression and Ridge Regression</a>.</li>

                <li><strong>Lecture 3 </strong> (09/09/2024 - 13:30-15:30) : <a href="MachineLearningMAPI3Lecture3ERM1.pdf" target="_blank" rel="noopener noreferrer">Empirical Risk Minimization 1</a>.</li>

                <li><strong>Lecture 4 </strong> (11/09/2024 - 13:30-15:30) : <a href="MachineLearningMAPI3Lecture4ERM2.pdf" target="_blank" rel="noopener noreferrer">Empirical Risk Minimization 2</a>.</li>

                <li><strong>Lecture 5 </strong> (16/09/2024 - 13:30-15:30) : <a href="MachineLearningMAPI3Lecture5Kernels1.pdf" target="_blank" rel="noopener noreferrer">Kernel Methods 1</a> <a href="https://members.cbio.mines-paristech.fr/~jvert/svn/kernelcourse/notes/aronszajn.pdf" target="_blank" rel="noopener noreferrer">(Jean-Philippe Vert's proof of Aronszajn's theorem)</a>.</li>

                <li><strong>Lecture 6 </strong> (18/09/2024 - 13:30-15:30) : </li>

                <li><strong>Lecture 7 </strong> (06/01/2025 - 13:30-15:30) : </li>

                <li><strong>Lecture 8 </strong> (08/01/2025 - 15:45-17:45) : </li>

                <li><strong>Lecture 9 </strong> (13/01/2025 - 13:30-15:30) : </li>
            </ul>

            <h2>TDs / TPs</h2>
            <ul>
                <li><strong>TD/TP 1 </strong> Group 1 (07/10/2024 - 13:30-15:30) - Group 2 (07/10/2024 - 15:45-17:45): <a href="TP1.ipynb" target="_blank" rel="noopener noreferrer">Linear Regression, Ridge Regression, (Cross-)Validation and Dimensionality Reduction</a> <a href="TP1_correction.ipynb" target="_blank" rel="noopener noreferrer">(solution)</a>.</li>

                <li><strong>TD/TP 2 </strong> Group 1 (14/10/2024 - 13:30-15:30) - Group 2 (14/10/2024 - 15:45-17:45) : </li>

                <li><strong>TD/TP 3 </strong> Group 1 (04/11/2024 - 13:30-15:30) - Group 2 (04/11/2024 - 15:45-17:45) : </li>

            </ul>
        </main>
    </div>
</body>
</html>